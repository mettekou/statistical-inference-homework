---
title: Statistical Inference - Homework 2
date: April 18, 2022
author: Dylan Meysmans (02113915)
output: pdf_document
---

```{r setup, include=FALSE}
library(MASS)
library(testforDEP)
data(LSAT)
```

1.  (a)

```{r 1a}
# The `cor` function calculates the Pearson sample correlation by default, the
# method argument is unnecessary
cor(LSAT$LSAT, LSAT$GPA)
```

(b)

```{r 1b}
set.seed(12345)
B <- 1000
cor.bootstrap <- vector(mode = "numeric", length = B)

for (i in 1:B) {
    j <- sample(1:dim(LSAT)[1], replace = TRUE)
    cor.bootstrap[i] <- cor(LSAT$LSAT[j], LSAT$GPA[j])
}

sd(cor.bootstrap)
hist(cor.bootstrap)
```

(c)

```{r 1c}
set.seed(12345)
B <- 1000
cor.bootstrap <- vector(mode = "numeric", length = B)
lsat.mean.estimate <- mean(LSAT$LSAT)
lsat.sd.estimate <- sd(LSAT$LSAT)
gpa.mean.estimate <- mean(LSAT$GPA)
gpa.sd.estimate <- sd(LSAT$GPA)
cor.estimate <- cor(LSAT$LSAT, LSAT$GPA)

mean.estimate <- c(lsat.mean.estimate, gpa.mean.estimate)
cov.estimate <- matrix(c(
    lsat.sd.estimate^2,
    lsat.sd.estimate * gpa.sd.estimate * cor.estimate,
    lsat.sd.estimate * gpa.sd.estimate * cor.estimate,
    gpa.sd.estimate^2
), 2)

for (i in 1:B) {
    lsat.bootstrap <- mvrnorm(dim(LSAT)[1], mean.estimate, cov.estimate)
    cor.bootstrap[i] <- cor(lsat.bootstrap[, 1], lsat.bootstrap[, 2])
}

sd(cor.bootstrap)
hist(cor.bootstrap)
```

(d) Assuming $\left(\text{LSAT},\text{GPA}\right)$ has a bivariate normal distribution

$$\text{SE}_r=\sqrt{\frac{\left(1-\rho^2\right)^2}{n}}=\frac{1-\rho^2}{\sqrt{n}}$$

When we fill in the sample correlation $r$ as an estimate for the correlation coefficient $\rho$ in the above formula, we obtain:

```{r 1d}
# The `cor` function calculates the Pearson sample correlation by default, the
# method argument is unnecessary
r <- cor(LSAT$LSAT, LSAT$GPA)
(1 - r^2) / sqrt(dim(LSAT)[1])
```

The estimate is lower than both bootstrap estimates.

(e) Let $\text{artanh}$, i.e. Fisher's z-transformation, be the transformation $g$, $\rho$ the parameter $\theta$, and $r$ the estimator $W_n$ in the Delta method. To find the asymptotic variance after transformation, we first find $g'$:

$$g'(\theta)$$

$$\frac{\sqrt{n}}{2}\left(\log\left(\frac{1+r}{1-r}\right)-\log\left(\frac{1+\rho}{1-\rho}\right)\right)\xrightarrow{D}N\left(0,1\right)$$

$$\sqrt{n}\left(\right)\xrightarrow{D}$$

(f) A variance stabilizing transformation makes the variance of a random variable independent from its mean. This is useful to e.g. satisfy the homoscedasticity assumption for ANOVA.

(g)

2.  (a) Since we know the sum of $n$ i.i.d. Poisson random variables with parameters $\lambda_1,\ldots,\lambda_n$ is a Poisson random variable with parameter $\sum_{i=1}^n \lambda_i$ and that scaling a Poisson random variable scales its mean $\lambda$ by the same factor, the pivot $Q$ becomes:

$$Q(\textbf{X},\lambda)=\frac{1}{\lambda}\sum_{i=1}^n X_i\sim\text{Poisson}(n)$$

The equations for $a$ and $b$ then become:

$$a$$

$$b$$

```{r}
set.seed(12345)

```

(b)
(c)
(d)